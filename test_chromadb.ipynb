{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from process_jobs import load_api_key, get_openai_embedding_function, load_and_clean_data, get_chroma_collection, build_vector_base, configure_retrievers, run_sample_query\n",
    "import pandas as pd\n",
    "import chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Démarrage du script de traitement des offres d'emploi...\n",
      "Fonction d'embedding OpenAI prête.\n",
      "Données chargées depuis jobsspider_2024-01-23T04-34-07+00-00.csv. Shape: (934, 9)\n",
      "Nettoyage des descriptions de poste...\n",
      "Nettoyage terminé.\n",
      "\n",
      "Exemple après nettoyage (avec localisation) :\n",
      "frg consulting recrutement pour l'un de ses clients, un cabinet de conseil à taille humaine basé à aix-en-provence, façonnant l'avenir des solutions innovantes pour leurs clients. dans le cadre de leur expansion, ils recherchent un data analyst junior h/f enthousiaste, spécialisé dans power bi, pour rejoindre une équipe dynamique. responsabilités analyser et extraire des insights significatifs à partir de données complexes. concevoir, développer et entretenir des tableaux de bord interactifs avec power bi. collaborer étroitement avec les équipes internes pour comprendre les exigences en données et proposer des solutions adaptées. contribuer à la collecte, au nettoyage et à la gestion efficace des données. profil recherché diplôme universitaire en statistiques, informatique, mathématiques appliquées ou domaine similaire. expertise approfondie de power bi. solides compétences en analyse de données et capacité à formuler des recommandations stratégiques. excellentes compétences en communication et aptitude à travailler en équipe. motivation à exceller dans un environnement de travail stimulant. technologies et stacks power bi (indispensable) sql, python (atouts majeurs) expérience avec des outils de visualisation de données avancés avantages environnement de travail collaboratif et innovant. possibilités de formation continue pour le développement professionnel. projets variés avec des clients diversifiés. Aix-en-Provence, Provence-Alpes-Côte d'Azur, France\n",
      "Client ChromaDB connecté à localhost:8000.\n",
      "Collection 'job' obtenue ou créée. Nombre actuel d'éléments : 934\n",
      "\n",
      "La collection 'job' contient déjà 934 éléments. Saut de build_vector_base.\n",
      "\n",
      "Configuration des retrievers...\n",
      "Retriever BM25 configuré.\n",
      "Retriever Chroma configuré.\n",
      "Ensemble Retriever (BM25 + Chroma) configuré.\n",
      "\n",
      "--- Test de la Recherche Hybride --- \n",
      "Requête : 'Data scientist avec experience en Python et machine learning à Paris'\n",
      "Erreur lors de la recherche avec EnsembleRetriever: 'OpenAIEmbeddingFunction' object has no attribute 'embed_query'\n",
      "\n",
      "Script terminé.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Yvank\\OneDrive - ESIGELEC\\Bureau\\chat_cv\\chat-cv\\process_jobs.py:190: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  hybrid_results = retriever.get_relevant_documents(query)\n"
     ]
    }
   ],
   "source": [
    "# --- Configuration ---\n",
    "JOB_DATA_FILE = 'jobsspider_2024-01-23T04-34-07+00-00.csv'\n",
    "CHROMA_HOST = 'localhost'\n",
    "CHROMA_PORT = 8000\n",
    "COLLECTION_NAME = \"job\"\n",
    "\n",
    "print(\"Démarrage du script de traitement des offres d'emploi...\")\n",
    "\n",
    "# 1. Charger la clé API et la fonction d'embedding\n",
    "api_key = load_api_key()\n",
    "if not api_key:\n",
    "    exit(1) # Arrêter si la clé API n'est pas trouvée\n",
    "    \n",
    "openai_embedding_func = get_openai_embedding_function(api_key)\n",
    "if not openai_embedding_func:\n",
    "        exit(1) # Arrêter si la fonction d'embedding échoue\n",
    "\n",
    "# 2. Charger et nettoyer les données\n",
    "job_data = load_and_clean_data(JOB_DATA_FILE)\n",
    "if job_data is None:\n",
    "    exit(1) # Arrêter si les données ne peuvent pas être chargées/nettoyées\n",
    "\n",
    "# 3. Initialiser le client ChromaDB\n",
    "try:\n",
    "    chroma_client = chromadb.HttpClient(host=CHROMA_HOST, port=CHROMA_PORT)\n",
    "    # Essayer de vérifier la connexion (ex: lister les collections)\n",
    "    chroma_client.list_collections() \n",
    "    print(f\"Client ChromaDB connecté à {CHROMA_HOST}:{CHROMA_PORT}.\")\n",
    "except Exception as e:\n",
    "    print(f\"Erreur de connexion au serveur ChromaDB à {CHROMA_HOST}:{CHROMA_PORT}: {e}\")\n",
    "    print(\"Vérifiez que le serveur ChromaDB est lancé (par exemple avec `chroma run --path /path/to/db`)\")\n",
    "    exit(1)\n",
    "\n",
    "# 4. Obtenir/Créer la collection ChromaDB\n",
    "job_collection = get_chroma_collection(chroma_client, COLLECTION_NAME, openai_embedding_func)\n",
    "if job_collection is None:\n",
    "    exit(1) # Arrêter si la collection ne peut pas être obtenue/créée\n",
    "\n",
    "# 5. Construire/Mettre à jour la base vectorielle (optionnel si déjà fait)\n",
    "# Décommentez la ligne suivante pour exécuter l'ajout à chaque fois\n",
    "# build_vector_base(job_data, job_collection) \n",
    "# OU: Vérifier si la collection est vide avant de construire\n",
    "if job_collection.count() < len(job_data): # Simple vérification, peut être affinée\n",
    "        print(\"\\nLa collection semble incomplète ou vide, lancement de build_vector_base...\")\n",
    "        build_vector_base(job_data, job_collection)\n",
    "else:\n",
    "        print(f\"\\nLa collection '{COLLECTION_NAME}' contient déjà {job_collection.count()} éléments. Saut de build_vector_base.\")\n",
    "\n",
    "\n",
    "# 6. Configurer les Retrievers\n",
    "hybrid_retriever = configure_retrievers(job_data, chroma_client, COLLECTION_NAME, openai_embedding_func)\n",
    "\n",
    "# 7. Exécuter une requête exemple\n",
    "if hybrid_retriever:\n",
    "    SAMPLE_QUERY = \"Data scientist avec experience en Python et machine learning à Paris\"\n",
    "    run_sample_query(hybrid_retriever, SAMPLE_QUERY)\n",
    "else:\n",
    "    print(\"\\nLe retriever hybride n'a pas pu être configuré. Le test de requête est sauté.\")\n",
    "    \n",
    "print(\"\\nScript terminé.\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-job",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
